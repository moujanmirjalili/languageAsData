{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7628c6ab",
   "metadata": {},
   "source": [
    "# Using mGPT for Zero-Shot and Few-Shot Translation\n",
    "This notebook demonstrates how to use mGPT for Zero-Shot and Few-Shot translation tasks.\n",
    "We use the `ai-forever/mGPT` model from Hugging Face's Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93091872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "# !pip install transformers\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cdaa6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(100000, 2048)\n",
       "    (wpe): Embedding(2048, 2048)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=6144, nx=2048)\n",
       "          (c_proj): Conv1D(nf=2048, nx=2048)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=8192, nx=2048)\n",
       "          (c_proj): Conv1D(nf=2048, nx=8192)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=100000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from src.translate import load_sent_cut_of_end\n",
    "example_sent = load_sent_cut_of_end(\"content/example_sent.txt\")\n",
    "# Load mGPT model and tokenizer\n",
    "model_name = 'ai-forever/mGPT'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef42982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc26752-86d9-413a-9293-0047f001e780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad319734",
   "metadata": {},
   "source": [
    "vocab_size = 100000, so this model is indeed mGPT(https://huggingface.co/ai-forever/mGPT) rather than GPT-2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c8a205",
   "metadata": {},
   "source": [
    "## Zero-Shot Translation\n",
    "We translate an English sentence to German without providing any examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9fa38ae-e63c-4a6c-81a4-a3db4e05c9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "لطفاً پنجره را باز کنید.\n"
     ]
    }
   ],
   "source": [
    "print(example_sent[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4efb288e-ddd0-46e1-92f4-acdb260e8d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]لطفاً پنجره را باز کنید. \n",
      "[1] Please open the window.\n",
      "[2]پنجره رو باز کن. \n",
      "[2] Open the window.\n",
      "[3]آیا می‌توانید به من کمک کنید؟ \n",
      "[3] How can I help you?\n",
      "[4]می‌تونی کمکم کنی؟ \n",
      "[4] I can help you?\n",
      "[5]لطفاً دفتر خود را به من بدهید. \n",
      "[5] Please let me know your office.\n",
      "[6]دفتر‌تو بده. \n",
      "[6] I will give you my office.\n",
      "[7]آیا امکانش هست که چند دقیقه صبر کنید؟ \n",
      "[7] Is it possible to wait for a few minutes?\n",
      "[8]میشه یه لحظه صبر کنی؟ \n",
      "[8] Can you wait for a moment?\n",
      "[9]امروز هوا آفتابی است. \n",
      "[9] Today the weather is sunny.\n",
      "[10]سیستم عامل نیاز به به‌روزرسانی دارد. \n",
      "[10] The operating system needs to be updated.\n",
      "[11]من عاشق کتاب خواندن هستم. \n",
      "[11] I am a lover of reading.\n",
      "[12]این الگوریتم برای کاهش زمان پردازش طراحی شده است. \n",
      "[12] This algorithm is designed to reduce the processing time.\n",
      "[13]یک فنجان قهوه لطفاً. \n",
      "[13] A cup of tea please.\n",
      "[14]دستگاه شما به وای‌فای متصل نیست. \n",
      "[14] Your device is not connected to the Wi-Fi.\n",
      "[15]من به خرید می‌روم. \n",
      "[15] I want to buy.\n",
      "[16]پایگاه داده به طور خودکار پشتیبان‌گیری می‌شود. \n",
      "[16] The database is automatically backed up.\n",
      "[17]من به خانه رفتم. \n",
      "[17] I went to the house.\n",
      "[18]بعد از این که کارم تمام شد، به خانه رفتم. \n",
      "[18] After I finished my work, I went to the house.\n",
      "[19]او کتاب را خرید. \n",
      "[19] I bought the book.\n",
      "[20]او کتابی را که دیروز دیدم خرید. \n",
      "[20] I bought a book yesterday.\n",
      "[21]ما فیلم دیدیم. \n",
      "[21] We watched the movie.\n",
      "[22]وقتی باران تمام شد، ما به تماشای فیلم رفتیم. \n",
      "[22] When the rain stopped, we went to see the movie.\n",
      "[23]او دوید. \n",
      "[23] I ride.\n",
      "[24]او به سمت درختی که در دوردست بود دوید. \n",
      "[24] He went to the tree that was in the dirt.\n",
      "[25]من امروز صبح ورزش کردم. \n",
      "[25] Today I was exercising.\n",
      "[26]من هر روز ورزش می‌کنم. \n",
      "[26] I exercise every day.\n",
      "[27]فردا صبح ورزش خواهم کرد. \n",
      "[27] Tomorrow I will go to the gym.\n",
      "[28]او کتابی خواند. \n",
      "[28] He read a book.\n",
      "[29]او کتابی می‌خواند. \n",
      "[29] He reads a book.\n",
      "[30]او کتابی خواهد خواند. \n",
      "[30] He will read a book.\n",
      "[31]ما به مسافرت رفتیم. \n",
      "[31] We went to the trip.\n",
      "[32]ما به مسافرت می‌رویم. \n",
      "[32] We are going to travel.\n",
      "[33]ما به مسافرت خواهیم رفت. \n",
      "[33] We are going to travel.\n",
      "[34]این جمله طعنه‌آمیز است. \n",
      "[34] This insulting sentence.\n",
      "[35]شما همیشه دیر می‌رسید. \n",
      "[35] You always was late.\n",
      "[36]آیا می‌توانید دلیل این موضوع را توضیح دهید؟ \n",
      "[36] Can you explain why this is happening?\n",
      "[37]هرچند خسته بودم، تا آخر شب بیدار ماندم. \n",
      "[37] I was tired, until the end of the night.\n",
      "[38]اگر باران نبارد، به پارک می‌رویم. \n",
      "[38] If rain falls, we go to the park.\n",
      "[39]کتابی که دیروز خریدی، کجاست؟ \n",
      "[39] A book you bought yesterday, where is it?\n",
      "[40]آن‌ها تصمیم گرفتند سفر را به تعویق بیاندازند. \n",
      "[40] They decided to delay their trip.\n"
     ]
    }
   ],
   "source": [
    "from src.translate import translate_multiple\n",
    "sentence=\"پنجره رو باز کن.\"\n",
    "start_lang=\"Persian\"\n",
    "target_language=\"English\"\n",
    "translate_multiple(example_sent,model,tokenizer,device,start_lang = \"Persian\", target_language=\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61f4b2a7-2bf4-4df5-90ae-ba5c12f2204d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful translator. Please translate the following English sentence into German. Do not add any extra text or explanations. Only provide the translation. \n",
      "\n",
      "English: Hello, how are you?\n",
      "German:\n"
     ]
    }
   ],
   "source": [
    "print(zero_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faab02ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Zero-Shot Translation: You are a helpful translator. Please translate the following English sentence into German. Do not add any extra text or explanations. Only provide the translation. \n",
      "\n",
      "English: Hello, how are you?\n",
      "German: Hallo, wie sind Sie?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the Zero-Shot prompt\n",
    "sentence_en = 'Hello, how are you?'\n",
    "zero_shot_prompt = (\n",
    "    \"You are a helpful translator. \"\n",
    "    \"Please translate the following English sentence into German. \"\n",
    "    \"Do not add any extra text or explanations. \"\n",
    "    \"Only provide the translation. \"\n",
    "    \"\\n\\n\"\n",
    "    \"English: Hello, how are you?\\n\"\n",
    "    \"German:\"\n",
    ")\n",
    "# Tokenize input\n",
    "inputs = tokenizer(zero_shot_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate output\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        num_beams=5,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "gen_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# post-process output'\n",
    "#if \"German:\" in gen_text:\n",
    " #   gen_text = gen_text.split(\"German:\")[-1].strip()\n",
    "\n",
    "print(\"Final Zero-Shot Translation:\", gen_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a943f81",
   "metadata": {},
   "source": [
    "## Few-Shot Translation\n",
    "We provide a few examples to guide the model in translating a new sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ed7a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Few-Shot Translation for 'The weather is nice today.'] \"Der Wetter ist schön heute.\"\n"
     ]
    }
   ],
   "source": [
    "def generate_few_shot_prompt(sentence):\n",
    "    return (\n",
    "        \"You are a helpful translator. \"\n",
    "        \"Please translate the following English sentences into German, \"\n",
    "        \"using the examples given. \"\n",
    "        \"Provide only the correct German translation, without any additional text or commentary.\\n\\n\"\n",
    "        \"Example 1:\\n[English]: \\\"Good morning.\\\"\\n[German]: \\\"Guten Morgen.\\\"\\n\"\n",
    "        \"Example 2:\\n[English]: \\\"I like to study languages.\\\"\\n[German]: \\\"Ich lerne gerne Sprachen.\\\"\\n\\n\"\n",
    "        f\"Now translate this sentence:\\n[English]: \\\"{sentence}\\\"\\n[German]:\"\n",
    "    )\n",
    "    \n",
    "sentence_to_translate = \"The weather is nice today.\"\n",
    "few_shot_prompt = generate_few_shot_prompt(sentence_to_translate)\n",
    "\n",
    "few_shot_inputs = tokenizer(few_shot_prompt, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    few_shot_outputs = model.generate(\n",
    "        **few_shot_inputs,\n",
    "        max_new_tokens=50, \n",
    "        num_beams=5,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "gen_text = tokenizer.decode(few_shot_outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "start_marker = f\"[English]: \\\"{sentence_to_translate}\\\"\\n[German]:\"\n",
    "if start_marker in gen_text:\n",
    "    gen_text = gen_text.split(start_marker)[-1].split(\"\\n\")[0].strip()\n",
    "else:\n",
    "    gen_text = \"Translation not found.\"\n",
    "\n",
    "print(f\"[Few-Shot Translation for '{sentence_to_translate}']\", gen_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665a983-8b87-4f04-b5f4-35bf60c15526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
